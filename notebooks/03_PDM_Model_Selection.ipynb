{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Selection & Benchmarking\n",
        "\n",
        "Objective: evaluate multiple candidate classifiers on the PdM dataset using the champion preprocessing pipeline (Feature Engineering ‚Üí OneHotEncoder + RobustScaler ‚Üí SMOTE) and log everything to MLflow (DagsHub) for traceability.\n",
        "\n",
        "**Models to test (initial batch):** Logistic Regression, Random Forest, Gradient Boosting, XGBoost.\n",
        "\n",
        "> Re-run after tweaking hyperparameters or adding new models as we learn more.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\mlflow\\utils\\requirements_utils.py:20: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  import pkg_resources  # noqa: TID251\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
        "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.metrics import (\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    ConfusionMatrixDisplay,\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "import mlflow\n",
        "import dagshub\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Physics-informed feature generator used across all models.\"\"\"\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        X[\"Power [W]\"] = X[\"Torque [Nm]\"] * (X[\"Rotational speed [rpm]\"] * (2 * np.pi / 60))\n",
        "        X[\"Temp Diff [K]\"] = X[\"Process temperature [K]\"] - X[\"Air temperature [K]\"]\n",
        "        X[\"Wear_Status\"] = pd.cut(\n",
        "            X[\"Tool wear [min]\"], bins=[-1, 60, 180, 300], labels=[0, 1, 2]\n",
        "        ).astype(int)\n",
        "        return X\n",
        "\n",
        "# Load raw data\n",
        "raw_df = pd.read_csv(\"../data/raw/ai4i2020.csv\")\n",
        "raw_df = raw_df.drop(columns=[\"UDI\", \"Product ID\"], axis=1)\n",
        "\n",
        "# Feature lists consumed by the ColumnTransformer after FeatureEngineer\n",
        "NUMERIC_FEATURES = [\n",
        "    \"Air temperature [K]\",\n",
        "    \"Process temperature [K]\",\n",
        "    \"Rotational speed [rpm]\",\n",
        "    \"Torque [Nm]\",\n",
        "    \"Tool wear [min]\",\n",
        "    \"Power [W]\",\n",
        "    \"Temp Diff [K]\",\n",
        "    \"Wear_Status\",\n",
        "]\n",
        "CATEGORICAL_FEATURES = [\"Type\"]\n",
        "\n",
        "X = raw_df.drop(columns=[\"Machine failure\", \"TWF\", \"HDF\", \"PWF\", \"OSF\", \"RNF\"], axis=1)\n",
        "y = raw_df[\"Machine failure\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tracking URI: https://dagshub.com/PrakashD2003/Smart-IIOT-Monitoring.mlflow\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as PrakashD2003\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as PrakashD2003\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"PrakashD2003/Smart-IIOT-Monitoring\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"PrakashD2003/Smart-IIOT-Monitoring\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository PrakashD2003/Smart-IIOT-Monitoring initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository PrakashD2003/Smart-IIOT-Monitoring initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 19:54:54 INFO mlflow.tracking.fluent: Experiment with name 'Predictive_Maintenance_IIOT_Model_Selection' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='mlflow-artifacts:/b2e5c5850d58468094c937aae6011e2e', creation_time=1765290295237, experiment_id='1', last_update_time=1765290295237, lifecycle_stage='active', name='Predictive_Maintenance_IIOT_Model_Selection', tags={}>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()\n",
        "\n",
        "CONFIG = {\n",
        "    \"experiment_name\": \"Predictive_Maintenance_IIOT_Model_Selection\",\n",
        "    \"random_state\": 42,\n",
        "    \"test_size\": 0.2,\n",
        "    \"DAGSHUB_REPO_OWNER\": os.getenv(\"DagsHub_Repo_Owner\"),\n",
        "    \"DAGSHUB_REPO_NAME\": os.getenv(\"DagsHub_Repo_Name\"),\n",
        "    \"DAGSHUB_TRACKING_URI\": os.getenv(\"DagsHub_MLflow_Tracking_URI\"),\n",
        "}\n",
        "\n",
        "# Initialize DagsHub-backed MLflow tracking\n",
        "print(\"Tracking URI:\", CONFIG[\"DAGSHUB_TRACKING_URI\"])\n",
        "dagshub.init(\n",
        "    repo_owner=CONFIG[\"DAGSHUB_REPO_OWNER\"],\n",
        "    repo_name=CONFIG[\"DAGSHUB_REPO_NAME\"],\n",
        "    mlflow=True,\n",
        ")\n",
        "mlflow.set_tracking_uri(CONFIG[\"DAGSHUB_TRACKING_URI\"])\n",
        "mlflow.set_experiment(CONFIG[\"experiment_name\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_model_params(algo_name: str, model) -> None:\n",
        "    \"\"\"Safely log hyperparameters to MLflow.\"\"\"\n",
        "    if mlflow.active_run() is None:\n",
        "        raise RuntimeError(\"No active MLflow run. Use mlflow.start_run().\")\n",
        "\n",
        "    params = model.get_params()\n",
        "    clean_params = {\n",
        "        k: v if isinstance(v, (int, float, str, bool)) else str(v) for k, v in params.items()\n",
        "    }\n",
        "    mlflow.log_params(clean_params)\n",
        "\n",
        "\n",
        "def build_pipeline(model):\n",
        "    \"\"\"Champion preprocessing + sampler + estimator.\"\"\"\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            (\"num\", RobustScaler(), NUMERIC_FEATURES),\n",
        "            (\n",
        "                \"cat\",\n",
        "                OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False),\n",
        "                CATEGORICAL_FEATURES,\n",
        "            ),\n",
        "        ],\n",
        "        remainder=\"drop\",\n",
        "    )\n",
        "\n",
        "    return ImbPipeline(\n",
        "        steps=[\n",
        "            (\"eng\", FeatureEngineer()),\n",
        "            (\"prep\", preprocessor),\n",
        "            (\"sampler\", SMOTE(random_state=CONFIG[\"random_state\"])),\n",
        "            (\"model\", model),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "def get_scores(pipeline, X_eval):\n",
        "    \"\"\"Return probability-like scores for ROC AUC.\"\"\"\n",
        "    if hasattr(pipeline, \"predict_proba\"):\n",
        "        return pipeline.predict_proba(X_eval)[:, 1]\n",
        "    if hasattr(pipeline, \"decision_function\"):\n",
        "        return pipeline.decision_function(X_eval)\n",
        "    return pipeline.predict(X_eval)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "candidate_models = {\n",
        "    \"LogReg\": LogisticRegression(max_iter=2000, solver=\"lbfgs\", n_jobs=-1),\n",
        "    \"RandomForest\": RandomForestClassifier(\n",
        "        n_estimators=300,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        random_state=CONFIG[\"random_state\"],\n",
        "        n_jobs=-1,\n",
        "    ),\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(random_state=CONFIG[\"random_state\"]),\n",
        "    \"XGBoost\": XGBClassifier(\n",
        "        n_estimators=400,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=5,\n",
        "        subsample=0.9,\n",
        "        colsample_bytree=0.9,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=CONFIG[\"random_state\"],\n",
        "        n_jobs=2,\n",
        "    ),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Models:   0%|          | 0/4 [00:19<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì LogReg: holdout recall=0.868, f1=0.296, auc=0.937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Models:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:19<00:59, 19.96s/it]d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\_distutils_hack\\__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
            "  warnings.warn(\n",
            "d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "Models:  25%|‚ñà‚ñà‚ñå       | 1/4 [02:10<00:59, 19.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì RandomForest: holdout recall=0.809, f1=0.696, auc=0.974\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Models:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [02:10<02:26, 73.47s/it]d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\_distutils_hack\\__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
            "  warnings.warn(\n",
            "d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "Models:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [02:32<02:26, 73.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì GradientBoosting: holdout recall=0.912, f1=0.551, auc=0.975\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Models:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [02:32<00:49, 49.91s/it]d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\_distutils_hack\\__init__.py:15: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
            "  warnings.warn(\n",
            "d:\\Conda\\envs\\smart-iiot\\Lib\\site-packages\\_distutils_hack\\__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
            "  warnings.warn(\n",
            "Models:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 3/4 [02:47<00:49, 49.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì XGBoost: holdout recall=0.838, f1=0.679, auc=0.980\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Models: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [02:47<00:00, 41.93s/it]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>cv_recall_mean</th>\n",
              "      <th>cv_recall_std</th>\n",
              "      <th>cv_f1_mean</th>\n",
              "      <th>cv_roc_auc_mean</th>\n",
              "      <th>cv_roc_auc_std</th>\n",
              "      <th>cv_time_seconds</th>\n",
              "      <th>holdout_recall</th>\n",
              "      <th>holdout_f1</th>\n",
              "      <th>holdout_roc_auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GradientBoosting</td>\n",
              "      <td>0.892862</td>\n",
              "      <td>0.032146</td>\n",
              "      <td>0.567393</td>\n",
              "      <td>0.977785</td>\n",
              "      <td>0.010637</td>\n",
              "      <td>6.398190</td>\n",
              "      <td>0.911765</td>\n",
              "      <td>0.551111</td>\n",
              "      <td>0.975083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogReg</td>\n",
              "      <td>0.830438</td>\n",
              "      <td>0.041916</td>\n",
              "      <td>0.281810</td>\n",
              "      <td>0.919683</td>\n",
              "      <td>0.012282</td>\n",
              "      <td>1.571934</td>\n",
              "      <td>0.867647</td>\n",
              "      <td>0.296482</td>\n",
              "      <td>0.937234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>0.826330</td>\n",
              "      <td>0.040531</td>\n",
              "      <td>0.726019</td>\n",
              "      <td>0.977017</td>\n",
              "      <td>0.010157</td>\n",
              "      <td>1.290008</td>\n",
              "      <td>0.838235</td>\n",
              "      <td>0.678571</td>\n",
              "      <td>0.979844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RandomForest</td>\n",
              "      <td>0.804310</td>\n",
              "      <td>0.045168</td>\n",
              "      <td>0.738947</td>\n",
              "      <td>0.973922</td>\n",
              "      <td>0.013828</td>\n",
              "      <td>3.461602</td>\n",
              "      <td>0.808824</td>\n",
              "      <td>0.696203</td>\n",
              "      <td>0.973625</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              model  cv_recall_mean  cv_recall_std  cv_f1_mean  \\\n",
              "2  GradientBoosting        0.892862       0.032146    0.567393   \n",
              "0            LogReg        0.830438       0.041916    0.281810   \n",
              "3           XGBoost        0.826330       0.040531    0.726019   \n",
              "1      RandomForest        0.804310       0.045168    0.738947   \n",
              "\n",
              "   cv_roc_auc_mean  cv_roc_auc_std  cv_time_seconds  holdout_recall  \\\n",
              "2         0.977785        0.010637         6.398190        0.911765   \n",
              "0         0.919683        0.012282         1.571934        0.867647   \n",
              "3         0.977017        0.010157         1.290008        0.838235   \n",
              "1         0.973922        0.013828         3.461602        0.808824   \n",
              "\n",
              "   holdout_f1  holdout_roc_auc  \n",
              "2    0.551111         0.975083  \n",
              "0    0.296482         0.937234  \n",
              "3    0.678571         0.979844  \n",
              "1    0.696203         0.973625  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results = []\n",
        "cv_splitter = StratifiedKFold(\n",
        "    n_splits=5, shuffle=True, random_state=CONFIG[\"random_state\"]\n",
        ")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Model_Selection\") as parent_run:\n",
        "    pbar = tqdm(candidate_models.items(), total=len(candidate_models), desc=\"Models\")\n",
        "\n",
        "    for model_name, model in candidate_models.items():\n",
        "        with mlflow.start_run(run_name=model_name, nested=True):\n",
        "            try:\n",
        "                start = time.time()\n",
        "                pipeline = build_pipeline(model)\n",
        "\n",
        "                cv_results = cross_validate(\n",
        "                    pipeline,\n",
        "                    X_train,\n",
        "                    y_train,\n",
        "                    cv=cv_splitter,\n",
        "                    scoring=[\"recall\", \"f1\", \"roc_auc\"],\n",
        "                    n_jobs=2,\n",
        "                )\n",
        "\n",
        "                elapsed = time.time() - start\n",
        "\n",
        "                cv_metrics = {\n",
        "                    \"cv_recall_mean\": cv_results[\"test_recall\"].mean(),\n",
        "                    \"cv_recall_std\": cv_results[\"test_recall\"].std(),\n",
        "                    \"cv_f1_mean\": cv_results[\"test_f1\"].mean(),\n",
        "                    \"cv_roc_auc_mean\": cv_results[\"test_roc_auc\"].mean(),\n",
        "                    \"cv_roc_auc_std\": cv_results[\"test_roc_auc\"].std(),\n",
        "                    \"cv_time_seconds\": elapsed,\n",
        "                }\n",
        "\n",
        "                # Fit once on the full training split for holdout evaluation\n",
        "                pipeline.fit(X_train, y_train)\n",
        "                y_pred = pipeline.predict(X_test)\n",
        "                y_scores = get_scores(pipeline, X_test)\n",
        "\n",
        "                holdout_metrics = {\n",
        "                    \"holdout_recall\": recall_score(y_test, y_pred),\n",
        "                    \"holdout_f1\": f1_score(y_test, y_pred),\n",
        "                    \"holdout_roc_auc\": roc_auc_score(y_test, y_scores),\n",
        "                }\n",
        "\n",
        "                # Log params & metrics\n",
        "                mlflow.log_params(\n",
        "                    {\n",
        "                        \"model_name\": model_name,\n",
        "                        \"encoder\": \"OneHotEncoder\",\n",
        "                        \"scaler\": \"RobustScaler\",\n",
        "                        \"sampler\": \"SMOTE\",\n",
        "                    }\n",
        "                )\n",
        "                log_model_params(model_name, model)\n",
        "                mlflow.log_metrics({**cv_metrics, **holdout_metrics})\n",
        "\n",
        "                # Confusion matrix artifact\n",
        "                disp = ConfusionMatrixDisplay.from_estimator(pipeline, X_test, y_test)\n",
        "                plt.title(f\"{model_name} Confusion Matrix (holdout)\")\n",
        "                plt.tight_layout()\n",
        "                cm_path = f\"confusion_matrix_{model_name}.png\"\n",
        "                plt.savefig(cm_path)\n",
        "                mlflow.log_artifact(cm_path)\n",
        "                plt.close()\n",
        "\n",
        "                # Save pipeline\n",
        "                mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")\n",
        "\n",
        "                pbar.write(\n",
        "                    f\"‚úì {model_name}: holdout recall={holdout_metrics['holdout_recall']:.3f}, \"\n",
        "                    f\"f1={holdout_metrics['holdout_f1']:.3f}, auc={holdout_metrics['holdout_roc_auc']:.3f}\"\n",
        "                )\n",
        "\n",
        "                results.append(\n",
        "                    {\n",
        "                        \"model\": model_name,\n",
        "                        **cv_metrics,\n",
        "                        **holdout_metrics,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            except Exception as e:\n",
        "                mlflow.log_param(\"status\", \"failed\")\n",
        "                mlflow.log_param(\"error\", str(e))\n",
        "                pbar.write(f\"‚úó {model_name}: {e}\")\n",
        "\n",
        "        pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.sort_values(by=\"holdout_recall\", ascending=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèÜ Report: Model Selection & Benchmarking\n",
        "\n",
        "**Date:** December 09, 2025\n",
        "**Author:** Prakash Dwivedi\n",
        "**Module:** Predictive Maintenance (PdM)\n",
        "**Experiment:** `03_PDM_Model_Selection.ipynb`\n",
        "\n",
        "-----\n",
        "\n",
        "![alt text](image.png)\n",
        "\n",
        "## 1\\. Objective\n",
        "\n",
        "Following the definition of our **Champion Preprocessing Pipeline** (RobustScaler + OneHotEncoder + SMOTE), the objective of this phase was to benchmark candidate Machine Learning algorithms to identify the best architecture for predicting machine failures.\n",
        "\n",
        "**Selection Criteria:**\n",
        "\n",
        "  * **Primary Metric:** **Recall** (Sensitivity). In PdM, missing a failure (False Negative) is the most expensive error.\n",
        "  * **Secondary Metric:** **ROC-AUC**. Measures the model's ability to rank failure risks correctly, allowing for flexible threshold tuning.\n",
        "  * **Sanity Check:** **F1-Score**. Ensures the model isn't just predicting \"Failure\" for everything (Precision check).\n",
        "\n",
        "-----\n",
        "\n",
        "## 2\\. Models Evaluated\n",
        "\n",
        "We evaluated four distinct model architectures to cover linear, bagging, and boosting approaches:\n",
        "\n",
        "1.  **Logistic Regression:** Linear baseline.\n",
        "2.  **Random Forest:** Bagging ensemble (Parallel trees).\n",
        "3.  **Gradient Boosting (sklearn):** Boosting ensemble (Sequential trees).\n",
        "4.  **XGBoost:** Advanced Gradient Boosting (Optimized for speed and performance).\n",
        "\n",
        "-----\n",
        "\n",
        "## 3\\. Experimental Results (Holdout Set)\n",
        "\n",
        "| Model Name | Recall (Catch Rate) | F1-Score (Balance) | ROC-AUC (Separability) | Status |\n",
        "| :--- | :--- | :--- | :--- | :--- |\n",
        "| **XGBoost** | **83.8%** | 67.9% | **0.980** | üèÜ **Champion** |\n",
        "| **Random Forest** | 80.9% | **69.6%** | 0.974 | ü•à Runner-up |\n",
        "| **Gradient Boosting** | 91.2% | 55.1% | 0.975 | Rejected (Low Precision) |\n",
        "| **Logistic Regression** | 86.8% | 29.6% | 0.937 | Rejected (Noise) |\n",
        "\n",
        "-----\n",
        "\n",
        "## 4\\. Analysis & Decision\n",
        "\n",
        "### A. The \"False Alarm\" Trap (Gradient Boosting & LogReg)\n",
        "\n",
        "  * **Gradient Boosting** achieved the highest Recall (91.2%), but the F1-Score (55.1%) indicates extremely low precision. It generates too many false alarms, which would cause \"alert fatigue\" for operators.\n",
        "  * **Logistic Regression** failed to distinguish complex patterns, resulting in a dismal F1-score of 29.6%.\n",
        "\n",
        "### B. The Top Contenders (XGBoost vs. Random Forest)\n",
        "\n",
        "This was a tight race between the two industry standards.\n",
        "\n",
        "  * **Random Forest** offered the best stability and precision (F1: 69.6%), but it missed \\~19% of failures (Recall: 80.9%).\n",
        "  * **XGBoost** caught significantly more failures (Recall: 83.8%) while maintaining a very similar F1-score (67.9%).\n",
        "\n",
        "### C. Why XGBoost Won?\n",
        "\n",
        "1.  **Superior Ranking (AUC 0.98):** XGBoost has the highest ROC-AUC, meaning it separates \"Healthy\" and \"Failing\" machines better than any other model.\n",
        "2.  **Recall Priority:** In our roadmap, we prioritized safety. Catching \\~3% more failures with XGBoost is worth the minor trade-off in precision.\n",
        "3.  **Future Proofing:** XGBoost handles missing values and outliers natively (if our pipeline ever leaks them) and scales better for larger datasets.\n",
        "\n",
        "-----\n",
        "\n",
        "## 5\\. Next Steps\n",
        "\n",
        "We will proceed with **XGBoost** as the core algorithm for the Predictive Maintenance module.\n",
        "\n",
        "**Immediate Tasks:**\n",
        "\n",
        "1.  **Hyperparameter Tuning:** Conduct a Bayesian or Grid Search on XGBoost to optimize:\n",
        "      * `scale_pos_weight` (To further balance precision/recall).\n",
        "      * `max_depth` (To prevent overfitting).\n",
        "      * `learning_rate` (For convergence).\n",
        "2.  **Final Training:** Train the tuned model on the full dataset and serialize it as `pdm_model.pkl`.\n",
        "\n",
        "3.  **Neural Networks:** Later we might move toward experimenting with neural networks when we have a `larger dataset` \n",
        ".\n",
        "\n",
        "-----\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "smart-iiot",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
